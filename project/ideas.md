# Link prediction using GNN



# Theory

An **adversarial attack** is a type of attack on a machine learning system which exploits the systemâ€™s weaknesses in order to produce a result that is different from the expected outcome. This is done by introducing small, carefully crafted changes to the input data in order to cause the system to make incorrect decisions.